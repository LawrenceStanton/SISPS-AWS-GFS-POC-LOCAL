{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Forecast System Proof of Concept\n",
    "\n",
    "This notebook is a proof of concept for working with the Global Forecast System (GFS). The GFS is a weather forecast model that publishes its data publicly to AWS S3. This notebook demonstrates how to access this data and plot it using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from logging import debug, info, warning, error, critical\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    stream=os.sys.stdout,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Download\n",
    "\n",
    "The first step is to download the data. The data is stored in the `noaa-gfs-bdp-pds` bucket on AWS S3. The data is organized by year, month, day, and hour.\n",
    "\n",
    "- Available GFS Parameter Sets: https://www.nco.ncep.noaa.gov/pmb/products/gfs/\n",
    "- AWS S3 Bucket: https://noaa-gfs-bdp-pds.s3.amazonaws.com/index.html\n",
    "\n",
    "The data is stored in GRIB2 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from typing import List, Literal\n",
    "\n",
    "\n",
    "def downloadGfsForecast(\n",
    "    saveDir: str,\n",
    "    forecastHours: int = 24,\n",
    "    gridResolution: Literal[\"1p00\", \"0p50\", \"0p25\"] = \"1p00\",\n",
    "    tNow: time.struct_time = time.gmtime(),\n",
    ") -> List[str]:\n",
    "    GFS_BUCKET_NAME = \"noaa-gfs-bdp-pds\"\n",
    "    GFS_BUCKET_REGION = \"us-east-1\"\n",
    "\n",
    "    s3 = boto3.resource(\n",
    "        \"s3\",\n",
    "        region_name=GFS_BUCKET_REGION,\n",
    "        config=Config(\n",
    "            signature_version=UNSIGNED,  # Unsigned as the bucket is public\n",
    "            max_pool_connections=100,  # Else get a warning\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    yyymmdd = time.strftime(\"%Y%m%d\")\n",
    "    lastHourlyQuarter = int(time.strftime(\"%H\", tNow)) // 6 * 6\n",
    "    hh = f\"{lastHourlyQuarter:02d}\"\n",
    "\n",
    "    bucketSubdir = f\"gfs.{yyymmdd}/{hh}/atmos\"\n",
    "    fileNames = [\n",
    "        f\"gfs.t{hh}z.pgrb2.{gridResolution}.f{i:03d}\"  # Assume pgrb2 as common parameter set\n",
    "        for i in range(0, forecastHours + 1)\n",
    "    ]\n",
    "\n",
    "    if gridResolution == \"0p50\" or gridResolution == \"1p00\":\n",
    "        debug(f\"{gridResolution} implies 3-hourly forecast intervals\")\n",
    "        fileNames = fileNames[::3]\n",
    "\n",
    "    os.makedirs(saveDir, exist_ok=True)\n",
    "\n",
    "    existingFiles = os.listdir(saveDir)\n",
    "\n",
    "    filesToDownload = [file for file in fileNames if file not in existingFiles]\n",
    "\n",
    "    def downloadFromS3(filename, saveDir=saveDir):\n",
    "        \"\"\"\n",
    "        Download process for a single GFS file from AWS S3\n",
    "        \"\"\"\n",
    "        info(f\"Downloading {filename}\")\n",
    "\n",
    "        try:\n",
    "            s3.Bucket(GFS_BUCKET_NAME).download_file(\n",
    "                f\"{bucketSubdir}/{filename}\",\n",
    "                f\"{saveDir}/{filename}\",\n",
    "            )\n",
    "        except Exception as e:\n",
    "            error(f\"Error downloading {filename}: {e}\")\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        executor.map(downloadFromS3, filesToDownload)\n",
    "\n",
    "    existingFiles = os.listdir(saveDir)  # Update list of existing files\n",
    "    for file in existingFiles:\n",
    "        if file not in fileNames:\n",
    "            warning(\n",
    "                f\"File {file} in {saveDir} is not part of the current forecast. Deleting.\"\n",
    "            )\n",
    "            os.remove(f\"{saveDir}/{file}\")\n",
    "\n",
    "    return os.listdir(saveDir)\n",
    "\n",
    "\n",
    "dataSaveDir = f\"Data/{time.strftime('%Y%m%d', time.gmtime())}\"\n",
    "forecastHours = 24 * 2\n",
    "forecastFiles = downloadGfsForecast(\n",
    "    saveDir=dataSaveDir,\n",
    "    gridResolution=\"0p50\",\n",
    "    forecastHours=forecastHours,\n",
    "    # Set time to be the current GMT time minus 6 hours to ensure that the latest forecast is downloaded\n",
    "    tNow=time.gmtime(time.time() - 6 * 3600),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "The `cfgrib` library is used to read the GRIB2 files. \n",
    "\n",
    "Example data is explored to understand the structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds = xr.open_dataset(\n",
    "    os.path.join(dataSaveDir, forecastFiles[0]),\n",
    "    engine=\"cfgrib\",\n",
    "    filter_by_keys={\n",
    "        \"typeOfLevel\": \"surface\",\n",
    "        \"stepType\": \"instant\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in ds:\n",
    "    print(f\"{v}\\t{ds[v].attrs['long_name']}, {ds[v].attrs['units']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = ds.get(\"t\")\n",
    "\n",
    "print(temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "`matplotlib` can plot the data with the appropriate projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitudes = temperature.latitude.values\n",
    "longitudes = temperature.longitude.values\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.SouthPolarStereo())\n",
    "\n",
    "t_celsius = temperature - 273.15\n",
    "t_celsius.plot(\n",
    "    ax=ax,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    cmap=\"coolwarm\",\n",
    "    cbar_kwargs={\"shrink\": 0.4},\n",
    ")\n",
    "\n",
    "ax.coastlines()\n",
    "ax.set_extent([-180, 180, -90, -60], ccrs.PlateCarree())\n",
    "ax.gridlines(\n",
    "    crs=ccrs.PlateCarree(),\n",
    "    draw_labels=True,\n",
    "    linewidth=1,\n",
    "    color=\"gray\",\n",
    "    alpha=0.5,\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "\n",
    "SANAE_IV = (-71.673611, -2.828611)\n",
    "ax.plot(\n",
    "    SANAE_IV[1],\n",
    "    SANAE_IV[0],\n",
    "    \"ro\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    label=\"SANAE IV\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Forecast\n",
    "\n",
    "The GFS data local to a specific location can be extracted and plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the temperature at SANAE IV and save as timeseries for all forecast files\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "temperatureForecast = []\n",
    "\n",
    "for file in forecastFiles:\n",
    "    ds = xr.open_dataset(\n",
    "        os.path.join(dataSaveDir, file),\n",
    "        engine=\"cfgrib\",\n",
    "        filter_by_keys={\n",
    "            \"typeOfLevel\": \"surface\",\n",
    "            \"stepType\": \"instant\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    temperature = ds.get(\"t\")\n",
    "    temperatureSanae = temperature.sel(\n",
    "        latitude=SANAE_IV[0], longitude=SANAE_IV[1], method=\"nearest\"\n",
    "    )\n",
    "    timeSanae = ds.valid_time.values\n",
    "\n",
    "    temperatureForecast.append((timeSanae, temperatureSanae.values - 273.15))\n",
    "\n",
    "temperatureForecast.sort(key=lambda x: x[0])\n",
    "temperatureForecast = pd.DataFrame(temperatureForecast, columns=[\"Time\", \"Temperature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"dark_background\"):\n",
    "    temperatureForecast.plot(\n",
    "        x=\"Time\",\n",
    "        y=\"Temperature\",\n",
    "        marker=\"o\",\n",
    "        title=\"Temperature forecast at SANAE IV\",\n",
    "        ylabel=\"Temperature [Â°C]\",\n",
    "        xlim=(\n",
    "            temperatureForecast.Time.min(),\n",
    "            temperatureForecast.Time.min() + pd.Timedelta(hours=forecastHours),\n",
    "        ),\n",
    "        figsize=(16, 9),\n",
    "        grid=True,\n",
    "        legend=False,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
